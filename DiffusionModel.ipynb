{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmajagQEwcDQZPX8qumD8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuel23taku/NoteBooks/blob/main/DiffusionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaGsy5UQaJJ2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.transforms import  ToTensor, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "# Other code\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "testing_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    training_data, batch_size = 1000,shuffle=True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    testing_data, batch_size = 1000,shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "train_features,train_labels = next(iter(train_dataloader))\n",
        "eg_image = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(eg_image)\n",
        "plt.title(label)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "-6_bqgV8bQS9",
        "outputId": "e8963da8-5d89-42f5-d961-bd1d45380102"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Diffusion Process"
      ],
      "metadata": {
        "id": "TekXHT7FbRII"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hRnYYw5RfDZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Util_DoubleConv(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,mid_channels=None): # mid_channels for number of neurons in the middle layer\n",
        "    super().__init__()\n",
        "    if not mid_channels:\n",
        "        mid_channels = out_channels\n",
        "    self.double_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(mid_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "class Util_DownScale(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super().__init__()\n",
        "    self.maxpool_conv = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        Util_DoubleConv(in_channels,out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.maxpool_conv(x)\n",
        "\n",
        "class Util_UpScale(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,bilinear=True): # Either use bilinear or transposed Conv2d\n",
        "    super().__init__()\n",
        "    if bilinear:\n",
        "      self.up = nn.Upsample(scale_factor=2,mode=\"bilinear\",align_corners=True)\n",
        "      self.conv = Util_DoubleConv(in_channels=in_channels,out_channels=out_channels,mid_channels= in_channels // 2)\n",
        "    else:\n",
        "      self.up = nn.ConvTranspose2d(in_channels=in_channels,out_channels=out_channels,kernel_size = 2,stride=2)\n",
        "      self.conv = Util_DoubleConv(in_channels,out_channels)\n",
        "\n",
        "  def forward(self,x1,x2):\n",
        "    '''\n",
        "        x2 is a skip connection value from the encoder,\n",
        "        while x1 is the decoder current state\n",
        "    '''\n",
        "\n",
        "    print(f\"Before passing x1 to upsample {x1}\")\n",
        "    x1 = self.up(x1)\n",
        "    print(f\"After passing x1 to upsample {x1}\")\n",
        "\n",
        "    # Compute height difference between x1 and x2\n",
        "    diffY = x2.size()[2] - x1.size()[2]\n",
        "    diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "    # Make x1 match the size of x2\n",
        "    x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "    # Do skip connection by concaticating tensor from different layers\n",
        "    x = torch.cat([x2,x1],dim=1)\n",
        "    self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class DiffusionUNet(nn.Module):\n",
        "    def __init__(self, in_channels, n_classes, bilinear=False):\n",
        "        super(DiffusionUNet, self).__init__()\n",
        "        self.n_channels = in_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = (Util_DoubleConv(in_channels, 64))\n",
        "        self.down1 = (Util_DownScale(64, 128))\n",
        "        self.down2 = (Util_DownScale(128, 256))\n",
        "        self.down3 = (Util_DownScale(256, 512))\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = (Util_DownScale(512, 1024 // factor))\n",
        "        self.up1 = (Util_UpScale(1024, 512 // factor, bilinear))\n",
        "        self.up2 = (Util_UpScale(512, 256 // factor, bilinear))\n",
        "        self.up3 = (Util_UpScale(256, 128 // factor, bilinear))\n",
        "        self.up4 = (Util_UpScale(128, 64, bilinear))\n",
        "        self.outc = (OutConv(64, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = self.inc(x)\n",
        "      x2 = self.down1(x1)\n",
        "      x3 = self.down2(x2)\n",
        "      x4 = self.down3(x3)\n",
        "      x5 = self.down4(x4)\n",
        "      x = self.up1(x5, x4)\n",
        "      x = self.up2(x, x3)\n",
        "      x = self.up3(x, x2)\n",
        "      x = self.up4(x, x1)\n",
        "      logits = self.outc(x)\n",
        "      return logits\n",
        "\n",
        "    def use_checkpointing(self):\n",
        "      self.inc = torch.utils.checkpoint(self.inc)\n",
        "      self.down1 = torch.utils.checkpoint(self.down1)\n",
        "      self.down2 = torch.utils.checkpoint(self.down2)\n",
        "      self.down3 = torch.utils.checkpoint(self.down3)\n",
        "      self.down4 = torch.utils.checkpoint(self.down4)\n",
        "      self.up1 = torch.utils.checkpoint(self.up1)\n",
        "      self.up2 = torch.utils.checkpoint(self.up2)\n",
        "      self.up3 = torch.utils.checkpoint(self.up3)\n",
        "      self.up4 = torch.utils.checkpoint(self.up4)\n",
        "      self.outc = torch.utils.checkpoint(self.outc)\n",
        "# The noising part\n",
        "def forward_diffusion(alphas_cumprod, x_start, t, noise):\n",
        "    batch_size, _, height, width = x_start.size()\n",
        "    # Expand alphas_cumprod[t] to match the shape of x_start and noise\n",
        "    alphas_cumprod_t = alphas_cumprod[t].view(batch_size, 1, 1, 1).expand(batch_size, 1, height, width).to(x_start.device)\n",
        "    return torch.sqrt(alphas_cumprod_t) * x_start + torch.sqrt(1 - alphas_cumprod_t) * noise\n"
      ],
      "metadata": {
        "id": "lZsJJ7OhfHJP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "Y_fIJZsvj_am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_alphas_cumprod(T):\n",
        "    betas = np.linspace(1e-4, 0.02, T)\n",
        "    alphas = 1 - betas\n",
        "    alphas_cumprod = np.cumprod(alphas)\n",
        "    return alphas_cumprod\n",
        "\n",
        "def train_model(train_loader,epoch_counts=30,lr=1e-3,weights_save_path = \"./weights\"):\n",
        "  T = 1000  # Number of diffusion steps\n",
        "  alphas_cumprod = get_alphas_cumprod(T)\n",
        "  alphas_cumprod = torch.tensor(alphas_cumprod).float()\n",
        "\n",
        "  model = DiffusionUNet(in_channels=1,n_classes=1,bilinear=False)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  loss_criterion = nn.MSELoss()\n",
        "# Generate alpha values to noise on each timestep\n",
        "  model.train()\n",
        "  for epoch in range(epoch_counts):\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data,_) in enumerate(train_loader):\n",
        "      data = data.view(-1,1,28,28) # Reshape and\n",
        "      t = torch.randint(0,T,(data.size(0),),dtype=torch.long)\n",
        "      noise = torch.randn_like(data)\n",
        "      x_t = forward_diffusion(alphas_cumprod,data,t,noise)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      predicted_noise = model(x_t)\n",
        "      print(f\"Predicted size {predicted_noise.size()}\")\n",
        "      print(f\"Original image size {data.size()}\")\n",
        "      loss = loss_criterion(predicted_noise, noise)\n",
        "      loss.backward()\n",
        "      # Update model weights\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader.dataset):.4f}')\n",
        "\n",
        "  # Save weights\n",
        "  torch.save(model.state_dict(),weights_save_path)\n",
        "\n",
        "train_model(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IoymBK6bkDyL",
        "outputId": "44e2af0b-c77b-4f85-caae-3b5c22cb4d8e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before passing x1 to upsample tensor([[[[0.7245]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.7238]],\n",
            "\n",
            "         [[0.8712]],\n",
            "\n",
            "         [[0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000]],\n",
            "\n",
            "         [[0.1905]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[1.1403]],\n",
            "\n",
            "         [[1.5633]],\n",
            "\n",
            "         [[0.5078]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.1926]],\n",
            "\n",
            "         [[0.0565]],\n",
            "\n",
            "         [[0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.8535]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.3069]],\n",
            "\n",
            "         [[0.9733]],\n",
            "\n",
            "         [[0.0123]]],\n",
            "\n",
            "\n",
            "        [[[0.2269]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         [[0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.1604]],\n",
            "\n",
            "         [[1.2376]],\n",
            "\n",
            "         [[0.0000]]]], grad_fn=<ReluBackward0>)\n",
            "After passing x1 to upsample tensor([[[[-0.0063, -0.3558],\n",
            "          [ 0.1893,  0.0346]],\n",
            "\n",
            "         [[ 0.0866, -0.4562],\n",
            "          [-0.3802,  0.0083]],\n",
            "\n",
            "         [[-0.0738, -0.1674],\n",
            "          [-0.6859,  0.2114]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1790, -0.0513],\n",
            "          [-0.5905, -0.4701]],\n",
            "\n",
            "         [[ 0.1264,  0.2755],\n",
            "          [-0.7501,  0.3437]],\n",
            "\n",
            "         [[-0.0341, -0.0404],\n",
            "          [-0.1821,  0.0903]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1774,  0.0866],\n",
            "          [-0.0630,  0.0142]],\n",
            "\n",
            "         [[-0.2164, -0.0956],\n",
            "          [-0.2069, -0.2436]],\n",
            "\n",
            "         [[ 0.0486,  0.0423],\n",
            "          [-0.1722,  0.2073]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3890, -0.1563],\n",
            "          [-0.0306, -0.1465]],\n",
            "\n",
            "         [[-0.1100,  0.3641],\n",
            "          [-0.5308,  0.0895]],\n",
            "\n",
            "         [[-0.0503, -0.3283],\n",
            "          [ 0.1301, -0.0767]]],\n",
            "\n",
            "\n",
            "        [[[-0.2205,  0.0797],\n",
            "          [-0.2837, -0.3016]],\n",
            "\n",
            "         [[-0.2400, -0.2677],\n",
            "          [-0.0065, -0.2193]],\n",
            "\n",
            "         [[-0.5873, -0.1206],\n",
            "          [-0.4963, -0.0232]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5248,  0.1805],\n",
            "          [-0.3750, -0.3777]],\n",
            "\n",
            "         [[ 0.2082,  0.2909],\n",
            "          [-0.4448,  0.3468]],\n",
            "\n",
            "         [[ 0.0907, -0.1709],\n",
            "          [-0.1044, -0.5347]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2841,  0.0535],\n",
            "          [-0.1378,  0.2264]],\n",
            "\n",
            "         [[ 0.0991, -0.5160],\n",
            "          [-0.0189,  0.2049]],\n",
            "\n",
            "         [[-0.4537, -0.4477],\n",
            "          [-0.2315,  0.0215]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.4284,  0.1984],\n",
            "          [-0.1560, -0.3034]],\n",
            "\n",
            "         [[ 0.0934,  0.1300],\n",
            "          [-0.6686, -0.2130]],\n",
            "\n",
            "         [[ 0.1195, -0.1733],\n",
            "          [-0.3600, -0.2922]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0182,  0.0128],\n",
            "          [ 0.0600,  0.3040]],\n",
            "\n",
            "         [[ 0.4742, -0.2452],\n",
            "          [-0.4360, -0.5439]],\n",
            "\n",
            "         [[-0.3957, -0.0599],\n",
            "          [-0.2001,  0.2361]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1626,  0.4476],\n",
            "          [-0.2892,  0.4557]],\n",
            "\n",
            "         [[ 0.0479, -0.2102],\n",
            "          [-0.3480,  0.3845]],\n",
            "\n",
            "         [[ 0.4248,  0.3191],\n",
            "          [ 0.0361, -0.0385]]],\n",
            "\n",
            "\n",
            "        [[[-0.2779,  0.2104],\n",
            "          [-0.1705, -0.1322]],\n",
            "\n",
            "         [[ 0.5485, -0.1718],\n",
            "          [-0.3232,  0.1286]],\n",
            "\n",
            "         [[ 0.0447, -0.5548],\n",
            "          [-0.5182, -0.2611]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.4360,  0.4222],\n",
            "          [-0.4393, -0.1547]],\n",
            "\n",
            "         [[-0.7442,  0.4605],\n",
            "          [-0.1749, -0.0424]],\n",
            "\n",
            "         [[ 0.1451, -0.3304],\n",
            "          [-0.1425, -0.1390]]]], grad_fn=<ConvolutionBackward0>)\n",
            "Before passing x1 to upsample None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "conv_transpose2d(): argument 'input' (position 1) must be Tensor, not NoneType",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d8ebc76dc9b1>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-d8ebc76dc9b1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, epoch_counts, lr, weights_save_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mpredicted_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted size {predicted_noise.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Original image size {data.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-d76a0418d569>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mx5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-d76a0418d569>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Before passing x1 to upsample {x1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"After passing x1 to upsample {x1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    950\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             output_padding, self.groups, self.dilation)\n",
            "\u001b[0;31mTypeError\u001b[0m: conv_transpose2d(): argument 'input' (position 1) must be Tensor, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Model Weights\n",
        "def load_model(model, load_path='model_weights.pth'):\n",
        "    model.load_state_dict(torch.load(load_path))\n",
        "    model.eval()\n",
        "    print(f'Model weights loaded from {load_path}')\n",
        "\n",
        "# Load the model weights\n",
        "load_model(model)\n",
        "\n",
        "# Sampling New Images\n",
        "def sample(model, num_samples=64):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.randn(num_samples, 1, 28, 28)  # Start with random noise\n",
        "        for t in reversed(range(T)):\n",
        "            predicted_noise = model(x)\n",
        "            x = (x - predicted_noise) / np.sqrt(get_alphas_cumprod()[t])\n",
        "    return x.cpu()\n",
        "\n",
        "# Generate new images\n",
        "generated_images = sample(model)\n",
        "\n",
        "# Plot the generated images\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(64):\n",
        "    plt.subplot(8, 8, i+1)\n",
        "    plt.imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kFStbwe-udSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
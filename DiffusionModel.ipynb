{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzj6OJMVD5pIMkoltzZ6aF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuel23taku/NoteBooks/blob/main/DiffusionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaGsy5UQaJJ2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.transforms import  ToTensor, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "# Other code\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "testing_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    training_data, batch_size = 1000,shuffle=True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    testing_data, batch_size = 1000,shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "train_features,train_labels = next(iter(train_dataloader))\n",
        "eg_image = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(eg_image)\n",
        "plt.title(label)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "-6_bqgV8bQS9",
        "outputId": "e59c398c-7083-47e5-e05b-3ed260526ab4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Diffusion Process"
      ],
      "metadata": {
        "id": "TekXHT7FbRII"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hRnYYw5RfDZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Util_DoubleConv(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,mid_channels=None): # mid_channels for number of neurons in the middle layer\n",
        "    super().__init__()\n",
        "    if not mid_channels:\n",
        "        mid_channels = out_channels\n",
        "    self.double_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(mid_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "class Util_DownScale(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super().__init__()\n",
        "    self.maxpool_conv = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        Util_DoubleConv(in_channels,out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.maxpool_conv(x)\n",
        "\n",
        "class Util_UpScale(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,bilinear=True): # Either use bilinear or transposed Conv2d\n",
        "    super().__init__()\n",
        "    if bilinear:\n",
        "      self.up = nn.Upsample(scale_factor=2,mode=\"bilinear\",align_corners=True)\n",
        "      self.conv = Util_DoubleConv(in_channels=in_channels,out_channels=out_channels,mid_channels= in_channels // 2)\n",
        "    else:\n",
        "      self.up = nn.ConvTranspose2d(in_channels=in_channels,out_channels=out_channels,kernel_size = 2,stride=2)\n",
        "      self.conv = Util_DoubleConv(in_channels,out_channels,mid_channels= in_channels // 2)\n",
        "\n",
        "  def forward(self,x1,x2):\n",
        "    '''\n",
        "        x2 is a skip connection value from the encoder,\n",
        "        while x1 is the decoder current state\n",
        "    '''\n",
        "\n",
        "    x1 = self.up(x1)\n",
        "\n",
        "    # Compute height difference between x1 and x2\n",
        "    diffY = x2.size()[2] - x1.size()[2]\n",
        "    diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "    # Make x1 match the size of x2\n",
        "    x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "    # Do skip connection by concaticating tensor from different layers\n",
        "    x = torch.cat([x2,x1],dim=1)\n",
        "\n",
        "    return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class DiffusionUNet(nn.Module):\n",
        "    def __init__(self, in_channels, n_classes, bilinear=False):\n",
        "        super(DiffusionUNet, self).__init__()\n",
        "        self.n_channels = in_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = (Util_DoubleConv(in_channels, 64))\n",
        "        self.down1 = (Util_DownScale(64, 128))\n",
        "        self.down2 = (Util_DownScale(128, 256))\n",
        "        self.down3 = (Util_DownScale(256, 512))\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = (Util_DownScale(512, 1024 // factor))\n",
        "        self.up1 = (Util_UpScale(1024, 512 // factor, bilinear))\n",
        "        self.up2 = (Util_UpScale(512, 256 // factor, bilinear))\n",
        "        self.up3 = (Util_UpScale(256, 128 // factor, bilinear))\n",
        "        self.up4 = (Util_UpScale(128, 64, bilinear))\n",
        "        self.outc = (OutConv(64, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = self.inc(x)\n",
        "      x2 = self.down1(x1)\n",
        "      x3 = self.down2(x2)\n",
        "      x4 = self.down3(x3)\n",
        "      x5 = self.down4(x4)\n",
        "      x = self.up1(x5, x4)\n",
        "      x = self.up2(x, x3)\n",
        "      x = self.up3(x, x2)\n",
        "      x = self.up4(x, x1)\n",
        "      logits = self.outc(x)\n",
        "      return logits\n",
        "\n",
        "    def use_checkpointing(self):\n",
        "      self.inc = torch.utils.checkpoint(self.inc)\n",
        "      self.down1 = torch.utils.checkpoint(self.down1)\n",
        "      self.down2 = torch.utils.checkpoint(self.down2)\n",
        "      self.down3 = torch.utils.checkpoint(self.down3)\n",
        "      self.down4 = torch.utils.checkpoint(self.down4)\n",
        "      self.up1 = torch.utils.checkpoint(self.up1)\n",
        "      self.up2 = torch.utils.checkpoint(self.up2)\n",
        "      self.up3 = torch.utils.checkpoint(self.up3)\n",
        "      self.up4 = torch.utils.checkpoint(self.up4)\n",
        "      self.outc = torch.utils.checkpoint(self.outc)\n",
        "# The noising part\n",
        "def forward_diffusion(alphas_cumprod, x_start, t, noise):\n",
        "    batch_size, _, height, width = x_start.size()\n",
        "    # Expand alphas_cumprod[t] to match the shape of x_start and noise\n",
        "    alphas_cumprod_t = alphas_cumprod[t].view(batch_size, 1, 1, 1).expand(batch_size, 1, height, width).to(x_start.device)\n",
        "    return torch.sqrt(alphas_cumprod_t) * x_start + torch.sqrt(1 - alphas_cumprod_t) * noise\n"
      ],
      "metadata": {
        "id": "lZsJJ7OhfHJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "Y_fIJZsvj_am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_alphas_cumprod(T):\n",
        "    betas = np.linspace(1e-4, 0.02, T)\n",
        "    alphas = 1 - betas\n",
        "    alphas_cumprod = np.cumprod(alphas)\n",
        "    return alphas_cumprod\n",
        "\n",
        "def train_model(train_loader,epoch_counts=30,lr=1e-3,weights_save_path = \"./weights\"):\n",
        "  T = 1000  # Number of diffusion steps\n",
        "  alphas_cumprod = get_alphas_cumprod(T)\n",
        "  alphas_cumprod = torch.tensor(alphas_cumprod).float()\n",
        "\n",
        "  model = DiffusionUNet(in_channels=1,n_classes=1,bilinear=False)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  loss_criterion = nn.MSELoss()\n",
        "# Generate alpha values to noise on each timestep\n",
        "  model.train()\n",
        "  for epoch in range(epoch_counts):\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data,_) in enumerate(train_loader):\n",
        "      data = data.view(-1,1,28,28) # Reshape and\n",
        "      t = torch.randint(0,T,(data.size(0),),dtype=torch.long)\n",
        "      noise = torch.randn_like(data)\n",
        "      x_t = forward_diffusion(alphas_cumprod,data,t,noise)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      predicted_noise = model(x_t)\n",
        "      print(f\"Predicted size {predicted_noise.size()}\")\n",
        "      print(f\"Original image size {data.size()}\")\n",
        "      loss = loss_criterion(predicted_noise, noise)\n",
        "      loss.backward()\n",
        "      # Update model weights\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader.dataset):.4f}')\n",
        "\n",
        "  # Save weights\n",
        "  torch.save(model.state_dict(),weights_save_path)\n",
        "\n",
        "train_model(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoymBK6bkDyL",
        "outputId": "9ff9f098-03fb-4711-cbd5-955cbcd85905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X before up1 torch.Size([1000, 1, 28, 28])\n",
            "Predicted size torch.Size([1000, 1, 28, 28])\n",
            "Original image size torch.Size([1000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Model Weights\n",
        "def load_model(model, load_path='model_weights.pth'):\n",
        "    model.load_state_dict(torch.load(load_path))\n",
        "    model.eval()\n",
        "    print(f'Model weights loaded from {load_path}')\n",
        "\n",
        "# Load the model weights\n",
        "load_model(model)\n",
        "\n",
        "# Sampling New Images\n",
        "def sample(model, num_samples=64):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.randn(num_samples, 1, 28, 28)  # Start with random noise\n",
        "        for t in reversed(range(T)):\n",
        "            predicted_noise = model(x)\n",
        "            x = (x - predicted_noise) / np.sqrt(get_alphas_cumprod()[t])\n",
        "    return x.cpu()\n",
        "\n",
        "# Generate new images\n",
        "generated_images = sample(model)\n",
        "\n",
        "# Plot the generated images\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(64):\n",
        "    plt.subplot(8, 8, i+1)\n",
        "    plt.imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kFStbwe-udSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
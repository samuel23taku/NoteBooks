{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBFBsNd4oql6Lo7E14yt5S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuel23taku/NoteBooks/blob/main/DiffusionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaGsy5UQaJJ2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.transforms import  ToTensor, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "# Other code\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "testing_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    training_data, batch_size = 1000,shuffle=True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    testing_data, batch_size = 1000,shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "train_features,train_labels = next(iter(train_dataloader))\n",
        "eg_image = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(eg_image)\n",
        "plt.title(label)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-6_bqgV8bQS9",
        "outputId": "3cca4c0a-42a1-4351-9e68-f5a659d23118"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 57271947.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1937179.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 13182115.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4137821.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Diffusion Process"
      ],
      "metadata": {
        "id": "TekXHT7FbRII"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hRnYYw5RfDZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Util_DoubleConv(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,mid_channels=None): # mid_channels for number of neurons in the middle layer\n",
        "    super().__init__()\n",
        "    if not mid_channels:\n",
        "      mid_channels = out_channels\n",
        "\n",
        "    self.double_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels,out_channels = mid_channels,kernel_size=3,padding=1),\n",
        "        nn.BatchNorm2d(mid_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(in_channels=mid_channels,out_channels = out_channels,kernel_size=3,padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "class Util_DownScale(nn.Module):\n",
        "  \"\"\" Downscaling with MaxPool the increase spartial res with Util_DoubleConv\"\"\"\n",
        "  def __init_(self,in_channels,out_channels,bilinear):\n",
        "    super().__init__()\n",
        "    self.maxpool_conv = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        Util_DoubleConv(in_channels,out_channels)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.maxpool_conv(x)\n",
        "\n",
        "class Util_UpScale(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,bilinear=True): # Either use bilinear or transposed Conv2d\n",
        "    super().__init__()\n",
        "    if bilinear:\n",
        "      self.up = nn.Upsample(scale_factor=2,mode=\"bilinear\",align_corner=True)\n",
        "      self.conv = Util_DoubleConv(in_channels=in_channels,out_channels=out_channels,mid_channels= in_channels // 2)\n",
        "    else:\n",
        "      self.up = nn.ConvTranspose2d(in_channels=in_channels,out_channels=out_channels)\n",
        "      self.conv = Util_DoubleConv(in_channels,out_channels)\n",
        "\n",
        "  def forward(self,x1,x2):\n",
        "    '''\n",
        "        x2 is a skip connection value from the encoder,\n",
        "        while x1 is the decoder current state\n",
        "    '''\n",
        "    x1 = self.up(x1)\n",
        "    # Compute height difference between x1 and x2\n",
        "    diffY = x2.size()[2] - x1.size()[2]\n",
        "    diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "    # Make x1 match the size of x2\n",
        "    x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "    # Do skip connection by concaticating tensor from different layers\n",
        "    x = torch.cat([x2,x1],dim=1)\n",
        "    self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class DiffusionUNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(DiffusionUNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = (Util_DoubleConv(n_channels, 64))\n",
        "        self.down1 = (Util_DownScale(64, 128))\n",
        "        self.down2 = (Util_DownScale(128, 256))\n",
        "        self.down3 = (Util_DownScale(256, 512))\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = (Util_DownScale(512, 1024 // factor))\n",
        "        self.up1 = (Util_UpScale(1024, 512 // factor, bilinear))\n",
        "        self.up2 = (Util_UpScale(512, 256 // factor, bilinear))\n",
        "        self.up3 = (Util_UpScale(256, 128 // factor, bilinear))\n",
        "        self.up4 = (Util_UpScale(128, 64, bilinear))\n",
        "        self.outc = (OutConv(64, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "    def use_checkpointing(self):\n",
        "        self.inc = torch.utils.checkpoint(self.inc)\n",
        "        self.down1 = torch.utils.checkpoint(self.down1)\n",
        "        self.down2 = torch.utils.checkpoint(self.down2)\n",
        "        self.down3 = torch.utils.checkpoint(self.down3)\n",
        "        self.down4 = torch.utils.checkpoint(self.down4)\n",
        "        self.up1 = torch.utils.checkpoint(self.up1)\n",
        "        self.up2 = torch.utils.checkpoint(self.up2)\n",
        "        self.up3 = torch.utils.checkpoint(self.up3)\n",
        "        self.up4 = torch.utils.checkpoint(self.up4)\n",
        "        self.outc = torch.utils.checkpoint(self.outc)\n",
        "# The noising part\n",
        "def forward_diffusion(alphas_cumprod, x_start, t, noise):\n",
        "    batch_size, _, height, width = x_start.size()\n",
        "    # Expand alphas_cumprod[t] to match the shape of x_start and noise\n",
        "    alphas_cumprod_t = alphas_cumprod[t].view(batch_size, 1, 1, 1).expand(batch_size, 1, height, width).to(x_start.device)\n",
        "    return torch.sqrt(alphas_cumprod_t) * x_start + torch.sqrt(1 - alphas_cumprod_t) * noise\n"
      ],
      "metadata": {
        "id": "lZsJJ7OhfHJP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "Y_fIJZsvj_am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_alphas_cumprod(T):\n",
        "    betas = np.linspace(1e-4, 0.02, T)\n",
        "    alphas = 1 - betas\n",
        "    alphas_cumprod = np.cumprod(alphas)\n",
        "    return alphas_cumprod\n",
        "\n",
        "def train_model(train_loader,epoch_counts=30,lr=1e-3,weights_save_path = \"./weights\"):\n",
        "  T = 1000  # Number of diffusion steps\n",
        "  alphas_cumprod = get_alphas_cumprod(T)\n",
        "  alphas_cumprod = torch.tensor(alphas_cumprod).float()\n",
        "  model = DiffusionU_NET(in_channels=1,out_channels=1)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  loss_criterion = nn.MSELoss()\n",
        "# Generate alpha values to noise on each timestep\n",
        "  model.train()\n",
        "  for epoch in range(epoch_counts):\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data,_) in enumerate(train_loader):\n",
        "      data = data.view(-1,1,28,28) # Reshape and\n",
        "      t = torch.randint(0,T,(data.size(0),),dtype=torch.long)\n",
        "      noise = torch.randn_like(data)\n",
        "      x_t = forward_diffusion(alphas_cumprod,data,t,noise)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      predicted_noise = model(x_t)\n",
        "      print(f\"Predicted size {predicted_noise.size()}\")\n",
        "      print(f\"Original image size {data.size()}\")\n",
        "      loss = loss_criterion(predicted_noise, noise)\n",
        "      loss.backward()\n",
        "      # Update model weights\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader.dataset):.4f}')\n",
        "\n",
        "  # Save weights\n",
        "  torch.save(model.state_dict(),weights_save_path)\n",
        "\n",
        "train_model(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "IoymBK6bkDyL",
        "outputId": "2e99f91a-f9ce-4f56-c584-4c5c85a50f11"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted size torch.Size([1000, 1, 7, 7])\n",
            "Original image size torch.Size([1000, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1000, 1, 28, 28])) that is different to the input size (torch.Size([1000, 1, 7, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (7) must match the size of tensor b (28) at non-singleton dimension 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-817481eeb27e>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-817481eeb27e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, epoch_counts, lr, weights_save_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted size {predicted_noise.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Original image size {data.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;31m# Update model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3363\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3365\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (28) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Model Weights\n",
        "def load_model(model, load_path='model_weights.pth'):\n",
        "    model.load_state_dict(torch.load(load_path))\n",
        "    model.eval()\n",
        "    print(f'Model weights loaded from {load_path}')\n",
        "\n",
        "# Load the model weights\n",
        "load_model(model)\n",
        "\n",
        "# Sampling New Images\n",
        "def sample(model, num_samples=64):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.randn(num_samples, 1, 28, 28)  # Start with random noise\n",
        "        for t in reversed(range(T)):\n",
        "            predicted_noise = model(x)\n",
        "            x = (x - predicted_noise) / np.sqrt(get_alphas_cumprod()[t])\n",
        "    return x.cpu()\n",
        "\n",
        "# Generate new images\n",
        "generated_images = sample(model)\n",
        "\n",
        "# Plot the generated images\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(64):\n",
        "    plt.subplot(8, 8, i+1)\n",
        "    plt.imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kFStbwe-udSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}